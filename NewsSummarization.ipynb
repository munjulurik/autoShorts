{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ChQyneCh6FF"
      },
      "source": [
        "## Getting Inshots Summaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNBJIWFAi8F0",
        "outputId": "eacbdbe4-b06a-440c-f154-729120770950"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting selenium\n",
            "  Downloading selenium-4.5.0-py3-none-any.whl (995 kB)\n",
            "\u001b[K     |████████████████████████████████| 995 kB 9.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.7/dist-packages (from selenium) (2022.9.24)\n",
            "Collecting trio-websocket~=0.9\n",
            "  Downloading trio_websocket-0.9.2-py3-none-any.whl (16 kB)\n",
            "Collecting trio~=0.17\n",
            "  Downloading trio-0.22.0-py3-none-any.whl (384 kB)\n",
            "\u001b[K     |████████████████████████████████| 384 kB 41.3 MB/s \n",
            "\u001b[?25hCollecting urllib3[socks]~=1.26\n",
            "  Downloading urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 43.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (2.10)\n",
            "Collecting sniffio\n",
            "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Collecting exceptiongroup>=1.0.0rc9\n",
            "  Downloading exceptiongroup-1.0.0-py3-none-any.whl (12 kB)\n",
            "Collecting async-generator>=1.9\n",
            "  Downloading async_generator-1.10-py3-none-any.whl (18 kB)\n",
            "Collecting outcome\n",
            "  Downloading outcome-1.2.0-py2.py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (22.1.0)\n",
            "Collecting wsproto>=0.14\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
            "Collecting h11<1,>=0.9.0\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 7.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from h11<1,>=0.9.0->wsproto>=0.14->trio-websocket~=0.9->selenium) (4.1.1)\n",
            "Installing collected packages: sniffio, outcome, h11, exceptiongroup, async-generator, wsproto, urllib3, trio, trio-websocket, selenium\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "requests 2.23.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you have urllib3 1.26.12 which is incompatible.\u001b[0m\n",
            "Successfully installed async-generator-1.10 exceptiongroup-1.0.0 h11-0.14.0 outcome-1.2.0 selenium-4.5.0 sniffio-1.3.0 trio-0.22.0 trio-websocket-0.9.2 urllib3-1.26.12 wsproto-1.2.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting newspaper3k\n",
            "  Downloading newspaper3k-0.2.8-py3-none-any.whl (211 kB)\n",
            "\u001b[K     |████████████████████████████████| 211 kB 8.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (4.6.3)\n",
            "Requirement already satisfied: Pillow>=3.3.0 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (7.1.2)\n",
            "Collecting tldextract>=2.0.1\n",
            "  Downloading tldextract-3.4.0-py3-none-any.whl (93 kB)\n",
            "\u001b[K     |████████████████████████████████| 93 kB 2.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=3.11 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (6.0)\n",
            "Collecting cssselect>=0.9.2\n",
            "  Downloading cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n",
            "Collecting tinysegmenter==0.3\n",
            "  Downloading tinysegmenter-0.3.tar.gz (16 kB)\n",
            "Requirement already satisfied: nltk>=3.2.1 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (3.7)\n",
            "Requirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (2.23.0)\n",
            "Collecting feedparser>=5.2.1\n",
            "  Downloading feedparser-6.0.10-py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 11.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (2.8.2)\n",
            "Collecting feedfinder2>=0.0.4\n",
            "  Downloading feedfinder2-0.0.4.tar.gz (3.3 kB)\n",
            "Requirement already satisfied: lxml>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (4.9.1)\n",
            "Collecting jieba3k>=0.35.1\n",
            "  Downloading jieba3k-0.35.1.zip (7.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.4 MB 28.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from feedfinder2>=0.0.4->newspaper3k) (1.15.0)\n",
            "Collecting sgmllib3k\n",
            "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk>=3.2.1->newspaper3k) (4.64.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk>=3.2.1->newspaper3k) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk>=3.2.1->newspaper3k) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk>=3.2.1->newspaper3k) (2022.6.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->newspaper3k) (2022.9.24)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 48.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->newspaper3k) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->newspaper3k) (2.10)\n",
            "Collecting requests-file>=1.4\n",
            "  Downloading requests_file-1.5.1-py2.py3-none-any.whl (3.7 kB)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from tldextract>=2.0.1->newspaper3k) (3.8.0)\n",
            "Building wheels for collected packages: tinysegmenter, feedfinder2, jieba3k, sgmllib3k\n",
            "  Building wheel for tinysegmenter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tinysegmenter: filename=tinysegmenter-0.3-py3-none-any.whl size=13553 sha256=75b4ea8e50382e1a42f8e566b010b5a827623b112c5f5ba9fa682fa3318a6aac\n",
            "  Stored in directory: /root/.cache/pip/wheels/df/67/41/faca10fa501ca010be41b49d40360c2959e1c4f09bcbfa37fa\n",
            "  Building wheel for feedfinder2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for feedfinder2: filename=feedfinder2-0.0.4-py3-none-any.whl size=3357 sha256=525661e3c6c84ea772935986c890ef0d1bf772fcc92cd10175cd17c40e581384\n",
            "  Stored in directory: /root/.cache/pip/wheels/7f/d4/8f/6e2ca54744c9d7292d88ddb8d42876bcdab5e6d84a21c10346\n",
            "  Building wheel for jieba3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jieba3k: filename=jieba3k-0.35.1-py3-none-any.whl size=7398404 sha256=2cec0286c0d79f7ebe52a77e15c9e846b168f90eb427aaf3f49b73baac512157\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/91/46/3c208287b726df325a5979574324878b679116e4baae1af3c3\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6066 sha256=4a7b0995f66dd2f2f1b896fbdfe638be90cea925a6b5e1db5ba7e1d963cb6cc4\n",
            "  Stored in directory: /root/.cache/pip/wheels/73/ad/a4/0dff4a6ef231fc0dfa12ffbac2a36cebfdddfe059f50e019aa\n",
            "Successfully built tinysegmenter feedfinder2 jieba3k sgmllib3k\n",
            "Installing collected packages: urllib3, sgmllib3k, requests-file, tldextract, tinysegmenter, jieba3k, feedparser, feedfinder2, cssselect, newspaper3k\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.26.12\n",
            "    Uninstalling urllib3-1.26.12:\n",
            "      Successfully uninstalled urllib3-1.26.12\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "selenium 4.5.0 requires urllib3[socks]~=1.26, but you have urllib3 1.25.11 which is incompatible.\u001b[0m\n",
            "Successfully installed cssselect-1.2.0 feedfinder2-0.0.4 feedparser-6.0.10 jieba3k-0.35.1 newspaper3k-0.2.8 requests-file-1.5.1 sgmllib3k-1.0.0 tinysegmenter-0.3 tldextract-3.4.0 urllib3-1.25.11\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Ign:2 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:7 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:8 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [83.3 kB]\n",
            "Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,332 kB]\n",
            "Hit:14 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [1,257 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,467 kB]\n",
            "Get:17 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [2,179 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [1,217 kB]\n",
            "Get:19 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [1,116 kB]\n",
            "Fetched 11.9 MB in 4s (2,993 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-codecs-ffmpeg-extra\n",
            "Suggested packages:\n",
            "  webaccounts-chromium-extension unity-chromium-extension\n",
            "The following NEW packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-chromedriver\n",
            "  chromium-codecs-ffmpeg-extra\n",
            "0 upgraded, 4 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 91.7 MB of archives.\n",
            "After this operation, 309 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-codecs-ffmpeg-extra amd64 105.0.5195.102-0ubuntu0.18.04.1 [1,156 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser amd64 105.0.5195.102-0ubuntu0.18.04.1 [80.1 MB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser-l10n all 105.0.5195.102-0ubuntu0.18.04.1 [5,097 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-chromedriver amd64 105.0.5195.102-0ubuntu0.18.04.1 [5,320 kB]\n",
            "Fetched 91.7 MB in 3s (30.6 MB/s)\n",
            "Selecting previously unselected package chromium-codecs-ffmpeg-extra.\n",
            "(Reading database ... 123942 files and directories currently installed.)\n",
            "Preparing to unpack .../chromium-codecs-ffmpeg-extra_105.0.5195.102-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-codecs-ffmpeg-extra (105.0.5195.102-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser.\n",
            "Preparing to unpack .../chromium-browser_105.0.5195.102-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-browser (105.0.5195.102-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser-l10n.\n",
            "Preparing to unpack .../chromium-browser-l10n_105.0.5195.102-0ubuntu0.18.04.1_all.deb ...\n",
            "Unpacking chromium-browser-l10n (105.0.5195.102-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-chromedriver.\n",
            "Preparing to unpack .../chromium-chromedriver_105.0.5195.102-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-chromedriver (105.0.5195.102-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-codecs-ffmpeg-extra (105.0.5195.102-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-browser (105.0.5195.102-0ubuntu0.18.04.1) ...\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n",
            "Setting up chromium-chromedriver (105.0.5195.102-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-browser-l10n (105.0.5195.102-0ubuntu0.18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.6) ...\n",
            "cp: '/usr/lib/chromium-browser/chromedriver' and '/usr/bin/chromedriver' are the same file\n"
          ]
        }
      ],
      "source": [
        "!pip install selenium\n",
        "!pip3 install newspaper3k\n",
        "!apt-get update # to update ubuntu to correctly run apt install\n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K0K76MIZu-7Q"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "from bs4 import BeautifulSoup\n",
        "from lxml import etree\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import time\n",
        "import json\n",
        "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.webdriver.common.by import By"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zUAgFCauMujh"
      },
      "outputs": [],
      "source": [
        "def getSource(elem):\n",
        "  return elem.find_all('div', class_='read-more')[0].a.text, elem.find_all('div', class_='read-more')[0].a['href']\n",
        "\n",
        "def getHeadline(elem):\n",
        "  return elem.find_all('div', class_='news-card-title')[0].span.text\n",
        "\n",
        "def getSummary(elem):\n",
        "  return elem.find_all('div', class_='news-card-content')[0].text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KEp_MdJ-yAY6"
      },
      "outputs": [],
      "source": [
        "def addTime_and_Author(elem):\n",
        "  author = elem.find_all('span', class_=\"author\")[0].text\n",
        "  timestamp = elem.find_all('span', class_=\"time\")[0]['content']\n",
        "\n",
        "  return timestamp, author"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFeF0I9Ju-4p",
        "outputId": "46560bc8-878a-4dc4-8c37-5b3d029974d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  6%|▌         | 116/2000 [03:32<57:23,  1.83s/it]\n"
          ]
        }
      ],
      "source": [
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_argument('--headless')\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "wd = webdriver.Chrome('chromedriver',options=chrome_options)\n",
        "wd.get(\"https://inshorts.com/en/read\")\n",
        "\n",
        "html = \"\"\n",
        "for i in tqdm(range(2000)):\n",
        "  try:\n",
        "    element = WebDriverWait(wd, 240).until(EC.element_to_be_clickable((By.XPATH, '//*[@id=\"load-more-btn\"]')))\n",
        "    element.click()\n",
        "  except:\n",
        "    break\n",
        "  if (i %100 ==0 ) and (i!=0):\n",
        "    html = wd.page_source"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DD8HB9_ou-11"
      },
      "outputs": [],
      "source": [
        "html = wd.page_source\n",
        "soup = BeautifulSoup(html)\n",
        "wd.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WF5cALoUu-ze",
        "outputId": "44ae8a91-4b83-46b8-ba5d-3da45f361645"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3113/3113 [00:05<00:00, 537.84it/s]\n"
          ]
        }
      ],
      "source": [
        "data = []\n",
        "exceptions = []\n",
        "for elem in tqdm(soup.find_all('div', class_='news-card z-depth-1')):\n",
        "  try:\n",
        "    source, source_url = getSource(elem)\n",
        "    timestamp, author = addTime_and_Author(elem)\n",
        "    if getHeadline(elem)!= \"\":\n",
        "      data.append((getHeadline(elem), getSummary(elem), source, source_url, timestamp, author))\n",
        "  except IndexError:\n",
        "    exceptions.append(elem)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmjgOQWpL_sd"
      },
      "source": [
        "## Getting original news data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IvMbTQylLlME"
      },
      "outputs": [],
      "source": [
        "from newspaper import Article\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D4439wYcsur1"
      },
      "outputs": [],
      "source": [
        "def get_article_data(url):\n",
        "  try:\n",
        "    article = Article(url)\n",
        "    article.download()\n",
        "    article.parse()\n",
        "    html = article.html\n",
        "    text = article.text\n",
        "    return html, text\n",
        "  except Exception as e:\n",
        "    return ('Error -' + str(e), \"\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def write_to_df(df):\n",
        "\n",
        "  df_org = pd.read_csv(\"/content/drive/MyDrive/InShorts/newsData.csv\", sep='|')\n",
        "\n",
        "  final = pd.concat([df_org, df])\n",
        "  final = final.drop_duplicates()\n",
        "\n",
        "  final.to_csv(\"/content/drive/MyDrive/InShorts/newsData.csv\", sep='|', index=False)\n",
        "\n",
        "  return final"
      ],
      "metadata": {
        "id": "4DbbJ_fPmhjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aum8mygFsupA"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(data, columns=['Headline', 'Summary', 'Source', 'URL', 'TimeStamp', 'Author'])\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-gCsqX8u7Dw",
        "outputId": "c582ad35-fe78-4eb4-d314-201e9ff2bfb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2760/2760 [48:27<00:00,  1.05s/it]\n"
          ]
        }
      ],
      "source": [
        "df[\"html\"], df[\"text\"] = zip(*df['URL'].progress_apply(get_article_data))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_news_properly(html, rule):\n",
        "  soup = BeautifulSoup(html)\n",
        "  if \"class_\" in rule.keys():\n",
        "    data = soup.find_all(rule['tag'], class_=rule['class_'])\n",
        "    if data != []:\n",
        "      if len(data) == 1:\n",
        "        return data[0].text\n",
        "      else:\n",
        "        pass\n",
        "    else:\n",
        "      return ''\n",
        "\n",
        "rule = {'Press Trust of India': {'class_':\"fulstorytext\", 'tag': 'p'}}"
      ],
      "metadata": {
        "id": "Z_bGBn_G7b4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['text'] = df.apply(lambda row: fetch_news_properly(row['html'], rule['Press Trust of India']) if row['Source']=='Press Trust of India' else row['text'], axis=1)"
      ],
      "metadata": {
        "id": "GFlPOsJYgJ8Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.read_csv('/content/drive/MyDrive/InShorts/newsData.csv', sep='|')\n",
        "\n",
        "news_df = pd.concat([df1, df[['Headline',\n",
        "  'Summary',\n",
        "  'Source',\n",
        "  'URL',\n",
        "  'TimeStamp',\n",
        "  'Author',\n",
        "  'text']]])\n",
        "\n",
        "news_df.to_csv('/content/drive/MyDrive/InShorts/newsData.csv', index=False, sep='|')"
      ],
      "metadata": {
        "id": "QsUCqvbKyICU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "news_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "ygIBn0aNqNaI",
        "outputId": "e6d90d71-1f4e-40c0-e0ac-e3574838e8de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            Headline  \\\n",
              "0  Forced to file FIR: MP health official after 3...   \n",
              "1  CBI raids 2 RJD leaders in Bihar in land for r...   \n",
              "2  India reports 10,649 new COVID-19 cases in 24 ...   \n",
              "3  Sonali said something fishy is going on, she c...   \n",
              "4  Meghan reveals she had to continue royal tour ...   \n",
              "\n",
              "                                             Summary           Source  \\\n",
              "0  \\nA medical officer in Madhya Pradesh's Bhind,...        The Quint   \n",
              "1  \\nCBI on Wednesday morning raided two Rashtriy...          Twitter   \n",
              "2  \\nIndia has reported 10,649 new COVID-19 cases...              PIB   \n",
              "3  \\nLate BJP leader Sonali Phogat's sister Rupes...              ANI   \n",
              "4  \\nMeghan Markle has revealed how she and Princ...  The Independent   \n",
              "\n",
              "                                                 URL  \\\n",
              "0  https://www.thequint.com/amp/story/news/india/...   \n",
              "1  https://twitter.com/ANI/status/156227508796093...   \n",
              "2  https://pib.gov.in/PressReleasePage.aspx?utm_c...   \n",
              "3  https://twitter.com/ANI/status/156225624415261...   \n",
              "4  https://www.independent.co.uk/life-style/royal...   \n",
              "\n",
              "                  TimeStamp          Author  \\\n",
              "0  2022-08-24T05:15:01.000Z     Atul Mishra   \n",
              "1  2022-08-24T03:54:55.000Z     Atul Mishra   \n",
              "2  2022-08-24T04:38:33.000Z    Apaar Sharma   \n",
              "3  2022-08-24T03:52:58.000Z    Apaar Sharma   \n",
              "4  2022-08-24T04:58:16.000Z  Ridham Gambhir   \n",
              "\n",
              "                                                text  \n",
              "0  A government official on whose complaint the p...  \n",
              "1  JavaScript is not available.\\n\\nWe’ve detected...  \n",
              "2  Ministry of Health and Family Welfare COVID-19...  \n",
              "3  JavaScript is not available.\\n\\nWe’ve detected...  \n",
              "4  Stay ahead of the trend in fashion and beyond ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-258d6de8-16f2-45dc-83c6-8f475780245b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Headline</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Source</th>\n",
              "      <th>URL</th>\n",
              "      <th>TimeStamp</th>\n",
              "      <th>Author</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Forced to file FIR: MP health official after 3...</td>\n",
              "      <td>\\nA medical officer in Madhya Pradesh's Bhind,...</td>\n",
              "      <td>The Quint</td>\n",
              "      <td>https://www.thequint.com/amp/story/news/india/...</td>\n",
              "      <td>2022-08-24T05:15:01.000Z</td>\n",
              "      <td>Atul Mishra</td>\n",
              "      <td>A government official on whose complaint the p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CBI raids 2 RJD leaders in Bihar in land for r...</td>\n",
              "      <td>\\nCBI on Wednesday morning raided two Rashtriy...</td>\n",
              "      <td>Twitter</td>\n",
              "      <td>https://twitter.com/ANI/status/156227508796093...</td>\n",
              "      <td>2022-08-24T03:54:55.000Z</td>\n",
              "      <td>Atul Mishra</td>\n",
              "      <td>JavaScript is not available.\\n\\nWe’ve detected...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>India reports 10,649 new COVID-19 cases in 24 ...</td>\n",
              "      <td>\\nIndia has reported 10,649 new COVID-19 cases...</td>\n",
              "      <td>PIB</td>\n",
              "      <td>https://pib.gov.in/PressReleasePage.aspx?utm_c...</td>\n",
              "      <td>2022-08-24T04:38:33.000Z</td>\n",
              "      <td>Apaar Sharma</td>\n",
              "      <td>Ministry of Health and Family Welfare COVID-19...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sonali said something fishy is going on, she c...</td>\n",
              "      <td>\\nLate BJP leader Sonali Phogat's sister Rupes...</td>\n",
              "      <td>ANI</td>\n",
              "      <td>https://twitter.com/ANI/status/156225624415261...</td>\n",
              "      <td>2022-08-24T03:52:58.000Z</td>\n",
              "      <td>Apaar Sharma</td>\n",
              "      <td>JavaScript is not available.\\n\\nWe’ve detected...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Meghan reveals she had to continue royal tour ...</td>\n",
              "      <td>\\nMeghan Markle has revealed how she and Princ...</td>\n",
              "      <td>The Independent</td>\n",
              "      <td>https://www.independent.co.uk/life-style/royal...</td>\n",
              "      <td>2022-08-24T04:58:16.000Z</td>\n",
              "      <td>Ridham Gambhir</td>\n",
              "      <td>Stay ahead of the trend in fashion and beyond ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-258d6de8-16f2-45dc-83c6-8f475780245b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-258d6de8-16f2-45dc-83c6-8f475780245b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-258d6de8-16f2-45dc-83c6-8f475780245b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Cleaning"
      ],
      "metadata": {
        "id": "5ipppWl5Kuif"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "o3Fb4BZrLWuV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "news_df = pd.read_csv(\"/content/drive/MyDrive/InShorts/newsData.csv\", sep='|')\n",
        "news_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLcgkQdKtdYh",
        "outputId": "746cfcf3-83f4-44b3-c013-fc03301d1ef1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(23259, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove all urls containing twitter.com and youtube.com, as they need to be scrapped differently\n",
        "news_df = news_df[news_df['URL'].str.contains(r'(twitter|facebook|youtube|Cleartrip|instagram|chess|youtu|flipkart|jigsawacademy|inshorts|wimbledon|vired|birmingham2022|amazon|shoppersstop|bseindia|onlinemanipal|usopen)\\.(in|com|be|org)')==False]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oixnhzb4Kx49",
        "outputId": "36130289-01b9-4b1c-a9c9-07a9e3b4fffc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# finding count of news sources\n",
        "source_dict = dict(zip(news_df['Source'].value_counts().index.tolist(), news_df['Source'].value_counts().values.tolist()))\n",
        "\n",
        "# dropping sources which have a count of 1. These are most likely advertisement cards on InShorts\n",
        "sources_to_drop = [k for k,v in source_dict.items() if v==1]\n",
        "\n",
        "# adding additional sources which are ads, such as Scaler\n",
        "sources_to_drop += ['Scaler', 'Goethe Institut', 'MOHFW', 'MoHFW', 'Abbot']\n",
        "\n",
        "print(\"Found a total of {} cards which are Advertisements\".format(len(sources_to_drop)))\n",
        "news_df = news_df[~news_df['Source'].isin(sources_to_drop)]\n",
        "\n",
        "source_dict = dict(zip(news_df['Source'].value_counts().index.tolist(), news_df['Source'].value_counts().values.tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0YCwffciYZYI",
        "outputId": "570341e2-9ea1-4e8a-f316-7f153d0f130a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found a total of 169 cards which are Advertisements\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "source = 'Times Now'\n",
        "indices = source_dict[source]\n",
        "np.random.seed(2)\n",
        "sample = np.random.randint(low=0, high=indices, size=4)\n",
        "for index in sample:\n",
        "  print(\"URL: {}\".format(news_df[news_df['Source']==source].iloc[index, 3]))\n",
        "  print()\n",
        "  print(index)\n",
        "  print()\n",
        "  print(news_df[news_df['Source']==source].iloc[index, 6])\n",
        "  print()\n",
        "  print()\n",
        "  print(\"*\"*100)\n",
        "  print(\"*\"*100)\n",
        "  print()\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4s2YEWYL0dY",
        "outputId": "61a14dd8-fcea-4d3e-ec7d-02ae2956678c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "URL: https://www.timesnownews.com/india/anti-national-slogans-raised-at-jammus-mam-college-after-pakistans-win-over-afghanistan-in-asia-cup-article-94077280/amp?utm_campaign=fullarticle&utm_medium=referral&utm_source=inshorts \n",
            "\n",
            "1192\n",
            "\n",
            "Anti-national slogans raised at Jammu’s MAM College after Pakistan’s win over Afghanistan in Asia Cup Asia Cup: Pakistan won the match yesterday and entered the finals to take on Sri Lanka over the weekend. Pakistan’s win also meant India are out of contention for a place in the final match. TN National Desk\n",
            "\n",
            "Anti-national slogans raised at Jammu’s MAM College after Pakistan’s win over Afghanistan in Asia Cup Photo : ANI\n",
            "\n",
            "Srinagar: Angry scenes were witnessed at the Angry scenes were witnessed at the MAM College in Jammu on Thursday as students staged a protest against anti-national slogans allegedly raised at the institution yesterday. It has been reported that a section of the students raised anti-India slogans at the MAM College following the Asia Cup 2022 match between Pakistan and Afghanistan\n",
            "\n",
            "Pakistan won the match yesterday and entered the finals to take on Sri Lanka over the weekend. Pakistan’s win also meant India are out of contention for a place in the final match.\n",
            "\n",
            "Today, a section of the students at the MAM College staged a protest against the alleged anti-national sloganeering witnessed yesterday.\n",
            "\n",
            "The principal of the MAM College, GS Rakwal, has assured strict action in the matter. He said the slogans were raised in the hostel.\n",
            "\n",
            "“We received complaints of anti-national slogans raised in the hostel after the match yesterday. We will take strict action,” Principal Rakwal said.\n",
            "\n",
            "Wednesday’s match ended in a thrilling finish with Pakistan securing a win in the last over against Afghanistan, which almost looked to have secured victory. If Pakistan had lost, India’s hopes of making it to the final would also have stayed alive.\n",
            "\n",
            "However, the Indian bid for a place in the final is now over and the team are slated to take on Afghanistan this evening in their last match of the ongoing tournament.\n",
            "\n",
            "\n",
            "****************************************************************************************************\n",
            "****************************************************************************************************\n",
            "\n",
            "\n",
            "URL: https://www.timesnownews.com/bengaluru/bbmp-polls-aap-to-contest-in-all-wards-invites-common-people-to-fight-and-win-elections-article-93061609/amp?utm_campaign=fullarticle&utm_medium=referral&utm_source=inshorts \n",
            "\n",
            "527\n",
            "\n",
            "BBMP polls: AAP to contest in all wards; invites 'common people to fight and win elections' BBMP elections 2022: Since September 2020, the Bruhat Bengaluru Mahanagara Palike has been without an elected council, leaving Bengaluru without local representation during emergency situations such as COVID-19, floods, pothole-filled roads, and increasing traffic jams. TN City Desk\n",
            "\n",
            "Pic courtesy: @AAPBangalore Photo : Twitter\n",
            "\n",
            "KEY HIGHLIGHTS The 2022 BBMP elections are expected to take place in October, as ordered by the Supreme Court\n",
            "\n",
            "The BBMP elections will serve as a semi-final to the 2023 Karnataka Assembly Elections\n",
            "\n",
            "Prime Minister Narendra Modi, during his visit to Bengaluru, highlighted his commitment to solving the traffic woes in the city\n",
            "\n",
            "Advertising Advertising\n",
            "\n",
            "Furthermore, he invited all Bengaluru residents wishing to contest in the upcoming elections to get in touch with the 'Candidate Search Committee'.\n",
            "\n",
            "\"As a part of the 'One Chance to Kejriwal' campaign, a Candidate Search Committee has been formed. Through this, we invite the common people, youth, women, advocates and people from different walks of life to fight and win elections,\" Reddy said.\n",
            "\n",
            "\"We will soon be celebrating 75 years of independence. However, it is unfortunate that now the democracy in our country has been reduced to 'of a group of exclusive people, by a group of exclusive people and for a group of exclusive people',\" he said.\n",
            "\n",
            "\"Delhi's honest governance has set a model for the rest of the country and now, Punjab has also created corruption-free governance. Why can this not be implemented in Bengaluru?\"\n",
            "\n",
            "\"People should come forward for Bengaluru. One step forward by the people will increase our strength. We all can together save Bengaluru,\" Reddy said.\n",
            "\n",
            "According to him, the AAP in Karnataka has been the sole opposition in the state for the past few years and the only party that has raised its voice against \"corruption, injustice and misgovernance of the BJP government\".\n",
            "\n",
            "\"Today, the AAP has its presence across the city and has been actively helping people with their problems and drawing everyone's attention to the problems in the city.\n",
            "\n",
            "\"Traditional parties have been doing politics all these days with money power and muscle power, and are focused on family politics,\" he added further.\n",
            "\n",
            "\n",
            "****************************************************************************************************\n",
            "****************************************************************************************************\n",
            "\n",
            "\n",
            "URL: https://www.timesnownews.com/india/sonia-gandhis-ed-questioning-congress-slams-centre-for-suppressing-oppns-voice-after-delhi-police-deny-permission-to-protest-article-93118878/amp?utm_campaign=fullarticle&utm_medium=referral&utm_source=inshorts \n",
            "\n",
            "493\n",
            "\n",
            "Sonia Gandhi’s ED questioning: Congress slams Centre for 'suppressing' Oppn's voice after Delhi Police deny permission to protest Congress president Sonia Gandhi is scheduled to appear before the ED on Tuesday for the second round of questioning. “We decided to hold a peaceful protest in front of Rajghat tomorrow (as Sonia Gandhi will appear before ED). We had given an application to Delhi Police for permission but they denied it,” said Congress General Secretary Organisation KC Venugopal. TN National Desk\n",
            "\n",
            "“It is unfortunate and condemnable. The government is suppressing the opposition’s voice” said Congress MP KC Venugopal. (Image: Twitter/@ANI) Photo : ANI\n",
            "\n",
            "New Delhi: on Monday slammed the Centre for “suppressing” the voice of Opposition after Congress on Monday slammed the Centre for “suppressing” the voice of Opposition after Delhi Police denied permission to protest at Rajghat in New Delhi on the day of Sonia Gandhi ’s questioning by the Enforcement Directorate (ED) in a money laundering case related to the National Herald newspaper.\n",
            "\n",
            "The Congress president is scheduled to appear before the ED on Tuesday for the second round of questioning. Initially, she was summoned by the agency on Monday but it was deferred by a day.\n",
            "\n",
            "“We decided to hold a peaceful protest in front of Rajghat tomorrow (as Sonia Gandhi will appear before ED). We had given an application to Delhi Police for permission but they denied it,” said Congress General Secretary Organisation KC Venugopal.\n",
            "\n",
            "“It is unfortunate and condemnable. The government is suppressing the opposition’s voice” said the Rajya Sabha MP.\n",
            "\n",
            "Gandhi was earlier questioned for over two hours on her first day of questioning in the case on July 21. During this, the 75-five-year-old Congress chief replied to 28 questions put forth by the agency.\n",
            "\n",
            "On the day, Congress leaders and workers staged a protest across the country. Party MPs had also courted arrest in Delhi against Gandhi’s questioning.\n",
            "\n",
            "Earlier former party chief Rahul Gandhi was also questioned by the probe agency.\n",
            "\n",
            "The move to question the Gandhis was initiated after the ED registered a fresh case under the criminal provisions of the Prevention of Money Laundering Act (PMLA) late last year. The agency is probing alleged financial irregularities in the Congress-promoted Young Indian Private Limited, which owns the National Herald newspaper\n",
            "\n",
            "This came after a Delhi court took cognisance of an Income Tax department probe against Young Indian, based on a private criminal complaint by Bharatiya Janata Party ( BJP ) MP Subramanian Swamy in 2013.\n",
            "\n",
            "Sonia and Rahul Gandhi are among the promoters and majority shareholders in Young Indian.\n",
            "\n",
            "\n",
            "****************************************************************************************************\n",
            "****************************************************************************************************\n",
            "\n",
            "\n",
            "URL: https://www.timesnownews.com/india/yogi-adityanath-gets-new-admirer-gangster-atiq-ahmad-calls-him-honest-brave-in-court-watch-article-94986904/amp?utm_campaign=fullarticle&utm_medium=referral&utm_source=inshorts \n",
            "\n",
            "1608\n",
            "\n",
            "Yogi Adityanath gets new admirer! Gangster Atiq Ahmad calls him honest, brave in court - WATCH Gangster Atiq Ahmad called Yogi Adityanath an honest, brave chief minister. He said that the BJP leader is a hard-working person. TN National Desk Updated Oct 20, 2022 | 03:55 PM IST\n",
            "\n",
            "Gangster Atiq Ahmad (left), Yogi Adityanath (Right)\n",
            "\n",
            "KEY HIGHLIGHTS Atiq Ahmad is a mafia-turned politician\n",
            "\n",
            "He joined AIMIM in 2021\n",
            "\n",
            "He is lodged in jail for killing a BSP leader\n",
            "\n",
            "Lucknow: Chief Minister Uttar Pradesh Chief Minister Yogi Adityanath , who is often termed as the firebrand BJP leader spearheading his bulldozer crackdown on the gangsters seems to have gotten himself yet another admirer-- this time a gangster himself. In a video, which is being widely circulating on social media, gangster Atiq Ahmad can be seen praising the chief minister, calling him honest and brave.\n",
            "\n",
            "Advertising Advertising\n",
            "\n",
            "Ahmad, who is a mafia-turned-politician from Samajwadi Party , made the statement when he was being taken to the CBI court in Lucknow for a hearing. Atiq Ahmad is lodged in Ahmedabad’s Sabarmati jail in connection with the murder of a former BSP leader.\n",
            "\n",
            "On being asked by the media about UP Chief Minister, Ahamd from the Lucknow court premises said in Hindi, “Yogi Adityanath ek imaandaar mukhyamantri hain aur bohot bahadur hain aur bohot mehnat karre hain.” (Yogi Adityanath is an honest and very brave chief minister and he is working really hard)\n",
            "\n",
            "WATCH THE VIDEO\n",
            "\n",
            "Who is Atiq Ahmad?\n",
            "\n",
            "A former member of parliament from UP’s Phulpur constituency, Atiq Ahmad is a mafia-turned-politician. He belongs to Akhilesh Yadav’s Samajwadi Party (SP).\n",
            "\n",
            "From 2004–2009, he was elected as SP’s candidate from Phulpur in Uttar Pradesh. Between the years 1999-2003, he was the president of the Apna Dal, founded by Sone Lal Patel.\n",
            "\n",
            "His political career experience a downfall when he was charged with the sensational murder of BSP MLA Raju Pal, who had defeated Atique's brother Ashraf in the 2004 Uttar Pradesh state legislature elections.\n",
            "\n",
            "On 15 December 2016, he was arrested once again for assaulting staff of the Sam Higginbottom University of Agriculture, Technology and Sciences.\n",
            "\n",
            "Ahmad fought the 2012 Assembly Elections under the Apna Dal banner, however, in the 2014 General Elections, he was taken back by the Samajwadi Party.\n",
            "\n",
            "Later in 2021, Ahmad joined Asaduddin Owaisi's AIMIM.\n",
            "\n",
            "\n",
            "****************************************************************************************************\n",
            "****************************************************************************************************\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "news_df['len'] = news_df['text'].apply(lambda x: len(str(x)))\n",
        "news_df = news_df[news_df['len']>3]"
      ],
      "metadata": {
        "id": "4Z-p4uXawEUC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "news_df['clean_summary'] = news_df['Summary'].apply(lambda x: x.split('\\n')[1])\n",
        "news_df['text'] = news_df['text'].apply(lambda x: x.replace('\\n', ''))\n",
        "news_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "b-pMZQr_fnyN",
        "outputId": "947197f7-a619-47ce-8998-207c0dcdd1de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            Headline  \\\n",
              "0  Forced to file FIR: MP health official after 3...   \n",
              "2  India reports 10,649 new COVID-19 cases in 24 ...   \n",
              "4  Meghan reveals she had to continue royal tour ...   \n",
              "5  I'll kill myself if athletes complain: UP offi...   \n",
              "6  Casemiro receives text from Real Madrid star's...   \n",
              "\n",
              "                                             Summary           Source  \\\n",
              "0  \\nA medical officer in Madhya Pradesh's Bhind,...        The Quint   \n",
              "2  \\nIndia has reported 10,649 new COVID-19 cases...              PIB   \n",
              "4  \\nMeghan Markle has revealed how she and Princ...  The Independent   \n",
              "5  \\nAfter UP Olympic Association's Secretary Gen...       The Bridge   \n",
              "6  \\nAfter midfielder Casemiro joined Manchester ...      Sportskeeda   \n",
              "\n",
              "                                                 URL  \\\n",
              "0  https://www.thequint.com/amp/story/news/india/...   \n",
              "2  https://pib.gov.in/PressReleasePage.aspx?utm_c...   \n",
              "4  https://www.independent.co.uk/life-style/royal...   \n",
              "5  https://thebridge.in/amp/others/lucknow-olympi...   \n",
              "6  https://www.sportskeeda.com/amp/football/news-...   \n",
              "\n",
              "                  TimeStamp          Author  \\\n",
              "0  2022-08-24T05:15:01.000Z     Atul Mishra   \n",
              "2  2022-08-24T04:38:33.000Z    Apaar Sharma   \n",
              "4  2022-08-24T04:58:16.000Z  Ridham Gambhir   \n",
              "5  2022-08-24T04:24:12.000Z    Anmol Sharma   \n",
              "6  2022-08-24T05:15:36.000Z    Anmol Sharma   \n",
              "\n",
              "                                                text   len  \\\n",
              "0  A government official on whose complaint the p...   536   \n",
              "2  Ministry of Health and Family Welfare COVID-19...   742   \n",
              "4  Stay ahead of the trend in fashion and beyond ...  4990   \n",
              "5  A series of photos showing highly-placed sport...  2472   \n",
              "6  Real Madrid midfielder Federico Valverde's gir...  2974   \n",
              "\n",
              "                                       clean_summary  \n",
              "0  A medical officer in Madhya Pradesh's Bhind, R...  \n",
              "2  India has reported 10,649 new COVID-19 cases a...  \n",
              "4  Meghan Markle has revealed how she and Prince ...  \n",
              "5  After UP Olympic Association's Secretary Gener...  \n",
              "6  After midfielder Casemiro joined Manchester Un...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3a8375b3-300f-4909-9da2-ec51b73d1eef\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Headline</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Source</th>\n",
              "      <th>URL</th>\n",
              "      <th>TimeStamp</th>\n",
              "      <th>Author</th>\n",
              "      <th>text</th>\n",
              "      <th>len</th>\n",
              "      <th>clean_summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Forced to file FIR: MP health official after 3...</td>\n",
              "      <td>\\nA medical officer in Madhya Pradesh's Bhind,...</td>\n",
              "      <td>The Quint</td>\n",
              "      <td>https://www.thequint.com/amp/story/news/india/...</td>\n",
              "      <td>2022-08-24T05:15:01.000Z</td>\n",
              "      <td>Atul Mishra</td>\n",
              "      <td>A government official on whose complaint the p...</td>\n",
              "      <td>536</td>\n",
              "      <td>A medical officer in Madhya Pradesh's Bhind, R...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>India reports 10,649 new COVID-19 cases in 24 ...</td>\n",
              "      <td>\\nIndia has reported 10,649 new COVID-19 cases...</td>\n",
              "      <td>PIB</td>\n",
              "      <td>https://pib.gov.in/PressReleasePage.aspx?utm_c...</td>\n",
              "      <td>2022-08-24T04:38:33.000Z</td>\n",
              "      <td>Apaar Sharma</td>\n",
              "      <td>Ministry of Health and Family Welfare COVID-19...</td>\n",
              "      <td>742</td>\n",
              "      <td>India has reported 10,649 new COVID-19 cases a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Meghan reveals she had to continue royal tour ...</td>\n",
              "      <td>\\nMeghan Markle has revealed how she and Princ...</td>\n",
              "      <td>The Independent</td>\n",
              "      <td>https://www.independent.co.uk/life-style/royal...</td>\n",
              "      <td>2022-08-24T04:58:16.000Z</td>\n",
              "      <td>Ridham Gambhir</td>\n",
              "      <td>Stay ahead of the trend in fashion and beyond ...</td>\n",
              "      <td>4990</td>\n",
              "      <td>Meghan Markle has revealed how she and Prince ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>I'll kill myself if athletes complain: UP offi...</td>\n",
              "      <td>\\nAfter UP Olympic Association's Secretary Gen...</td>\n",
              "      <td>The Bridge</td>\n",
              "      <td>https://thebridge.in/amp/others/lucknow-olympi...</td>\n",
              "      <td>2022-08-24T04:24:12.000Z</td>\n",
              "      <td>Anmol Sharma</td>\n",
              "      <td>A series of photos showing highly-placed sport...</td>\n",
              "      <td>2472</td>\n",
              "      <td>After UP Olympic Association's Secretary Gener...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Casemiro receives text from Real Madrid star's...</td>\n",
              "      <td>\\nAfter midfielder Casemiro joined Manchester ...</td>\n",
              "      <td>Sportskeeda</td>\n",
              "      <td>https://www.sportskeeda.com/amp/football/news-...</td>\n",
              "      <td>2022-08-24T05:15:36.000Z</td>\n",
              "      <td>Anmol Sharma</td>\n",
              "      <td>Real Madrid midfielder Federico Valverde's gir...</td>\n",
              "      <td>2974</td>\n",
              "      <td>After midfielder Casemiro joined Manchester Un...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3a8375b3-300f-4909-9da2-ec51b73d1eef')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3a8375b3-300f-4909-9da2-ec51b73d1eef button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3a8375b3-300f-4909-9da2-ec51b73d1eef');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cleaning_data_dict = {\"Hindustan Times\": [\"{{^userSubscribed}} {{/userSubscribed}}\",  \"SHARE THIS ARTICLE ON\"], \n",
        "                      \"Times Now\": ['Representational image.', 'Image:', ' TikTok/@', 'Advertising Advertising', 'Photo:'],\n",
        "                      \"Reuters\": ['Our Standards: The Thomson Reuters Trust Principles.', 'Reporting by', 'Register now for FREE unlimited access to Reuters.com Register'],\n",
        "                      \"The Print\": ['Also read:', 'This report is auto-generated'],\n",
        "                      \"News18\": ['Read the Latest News and Breaking News here', 'Read all the Latest News and Breaking News here', 'Read all the Latest News, Breaking News, watch Top Videos and Live TV here.', 'Advertisement'],\n",
        "                      \"Free Press Journal\": ['Advertisement', 'ALSO READ'],\n",
        "                      \"Moneycontrol\": [\"Read more:\"],\n",
        "                      \"ANI News\": [],\n",
        "                      \"Sportskeeda\": [\"Ad\", \"Quick Links\", \"Edited by\", \"last_line\"],\n",
        "                      \"The Siasat Daily\": [],\n",
        "                      \"Press Trust of India\": [], \n",
        "                      \"The Associated Press\": ['ADVERTISEMENT'],\n",
        "                      \"PINKVILLA\": [],\n",
        "                      \"LatestLY\": [\"Watch Video:\", \"Representative Image\", \"View Tweet Here:\", \"Representational Picture\"],\n",
        "                      \"ANI\": [],\n",
        "                      \"Financial Express\": [\"Also Read|\", \"Also Read:\", \"Watch Video |\", \"Watch Video|\", \"Watch Video:\"],\n",
        "                      \"The Quint\": [],\n",
        "                      \"CricTracker\": []}"
      ],
      "metadata": {
        "id": "zLoI7DFRSCPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save a copy of cleaned data\n",
        "news_df.to_csv('/content/drive/MyDrive/InShorts/newsDataCleaned.csv', sep='|', index=False)"
      ],
      "metadata": {
        "id": "3a60vv963s-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Building"
      ],
      "metadata": {
        "id": "0sUvseVyzxzz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install datasets transformers rouge-score nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYzQIVNYXB_3",
        "outputId": "d0e0765d-b922-42f3-dadc-33842f39be81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.6.1-py3-none-any.whl (441 kB)\n",
            "\u001b[K     |████████████████████████████████| 441 kB 7.2 MB/s \n",
            "\u001b[?25hCollecting transformers\n",
            "  Downloading transformers-4.24.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.5 MB 68.3 MB/s \n",
            "\u001b[?25hCollecting rouge-score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.7)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.1.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 60.5 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0.0,>=0.2.0\n",
            "  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n",
            "\u001b[K     |████████████████████████████████| 163 kB 75.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.13.0)\n",
            "Collecting dill<0.3.6\n",
            "  Downloading dill-0.3.5.1-py2.py3-none-any.whl (95 kB)\n",
            "\u001b[K     |████████████████████████████████| 95 kB 6.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py37-none-any.whl (115 kB)\n",
            "\u001b[K     |████████████████████████████████| 115 kB 77.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.3)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (22.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.1.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.8.1)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 74.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 47.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from rouge-score) (1.3.0)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from rouge-score) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.10.0)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.13-py37-none-any.whl (115 kB)\n",
            "\u001b[K     |████████████████████████████████| 115 kB 59.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Building wheels for collected packages: rouge-score\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24955 sha256=7d3fbd6918715259a031bfcd0afb5577863e069a1a2b74540c5a644c75300994\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/ac/6b/38096e3c5bf1dc87911e3585875e21a3ac610348e740409c76\n",
            "Successfully built rouge-score\n",
            "Installing collected packages: urllib3, dill, xxhash, tokenizers, responses, multiprocess, huggingface-hub, transformers, rouge-score, datasets\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.6\n",
            "    Uninstalling dill-0.3.6:\n",
            "      Successfully uninstalled dill-0.3.6\n",
            "Successfully installed datasets-2.6.1 dill-0.3.5.1 huggingface-hub-0.10.1 multiprocess-0.70.13 responses-0.18.0 rouge-score-0.1.2 tokenizers-0.13.1 transformers-4.24.0 urllib3-1.25.11 xxhash-3.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "from datasets import Dataset, DatasetDict, load_metric\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer, AutoConfig\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import numpy as np\n",
        "\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nh6eeAcT5UyA",
        "outputId": "61c69fd5-2972-46f6-a9bc-c55c9bf7aa25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load the dataset\n",
        "news_df = pd.read_csv('/content/drive/MyDrive/InShorts/newsDataCleaned.csv', sep='|')\n",
        "news_df = news_df[['text', 'clean_summary']]\n",
        "\n",
        "# found some None values for some reason, dropping them here temporarily\n",
        "news_df = news_df[~news_df['text'].isna()]\n",
        "news_df.dropna(inplace=True)\n",
        "train, test = train_test_split(news_df, test_size=0.1, random_state=12)\n",
        "\n",
        "train_data = Dataset.from_pandas(train)\n",
        "test_data = Dataset.from_pandas(test)\n",
        "\n",
        "dataset = DatasetDict()\n",
        "dataset['train'] = train_data\n",
        "dataset['test'] = test_data\n",
        "\n",
        "dataset"
      ],
      "metadata": {
        "id": "J2hIeNKMXB4n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb38952b-2284-4406-fa00-08d4254fda3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'clean_summary', '__index_level_0__'],\n",
              "        num_rows: 17832\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'clean_summary', '__index_level_0__'],\n",
              "        num_rows: 1982\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizing the data\n",
        "\n",
        "model_to_use = \"t5-small\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_to_use)\n",
        "\n",
        "if model_to_use.startswith('t5'):\n",
        "    prefix = \"summarize: \"\n",
        "else:\n",
        "    prefix = \"\"\n",
        "\n",
        "max_input_length = 2048\n",
        "max_target_length = 128\n",
        "\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    inputs = [prefix + doc for doc in examples[\"text\"]]\n",
        "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
        "\n",
        "    # Setup the tokenizer for targets\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(examples[\"clean_summary\"], max_length=max_target_length, truncation=True)\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs\n",
        "\n",
        "\n",
        "tokenized_datasets = dataset.map(preprocess_function, batched=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135,
          "referenced_widgets": [
            "9b7ad4aabbe741f18c154d9bd80fd5da",
            "83a669bd26094721bbf0bb8d280b3d05",
            "bd4de906555f40afbec94547f6a6bef2",
            "0e7e1786fcf9455096a77d775ca1bc3c",
            "c6409341560c4815832fc97b57712598",
            "52233d0e19b341ba9af34ea427c4625d",
            "d938f1c9bb46401aad40ee6c29b31581",
            "478399f05a6d40aa8adc2c7400946b64",
            "89b3b7757f384910831587ab2ef51727",
            "43a53d1ea5444527a7880a77888acc67",
            "6495e9dd90254951a2c7c1974ee94025",
            "2b3b24a7a1284f8490c876659726ff6c",
            "a222c04b91cb4b6f9ecd2872f675b478",
            "0b451ad8e7fc4606bff152335fd75bd0",
            "ebdb75fcefd34952b57936c49878a957",
            "97b57c6de31b4aa6bd076349c8be97cf",
            "8dd1d604e25b4a5e8c31635706bb9461",
            "8937b94f34e44105b92a6a1ae33b9dea",
            "ca2b7bf9d5d74777ae9babf688a0689e",
            "360bf60a0a1b4a688270eab7c1ad0d34",
            "9ef1d4afb41b4ff08358cedf27122e8a",
            "7106a86cb69b4c378859850587d89c69"
          ]
        },
        "id": "WWcyldNh8A9q",
        "outputId": "2f2561b9-046f-433c-d251-b42d9d165fcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/18 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9b7ad4aabbe741f18c154d9bd80fd5da"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:3547: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  \"`as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your \"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2b3b24a7a1284f8490c876659726ff6c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# function to compute metrics\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "    # Replace -100 in the labels as we can't decode them.\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "    \n",
        "    # Rouge expects a newline after each sentence\n",
        "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
        "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
        "    \n",
        "    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
        "    # Extract a few results\n",
        "    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
        "    \n",
        "    # Add mean generated length\n",
        "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
        "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
        "    \n",
        "    return {k: round(v, 4) for k, v in result.items()}"
      ],
      "metadata": {
        "id": "StCU5nFgCnu1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using the model and fine tuning\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_to_use)\n",
        "metric = load_metric(\"rouge\")\n",
        "\n",
        "batch_size = 4\n",
        "model_name = model_to_use.split(\"/\")[-1]\n",
        "args = Seq2SeqTrainingArguments(\n",
        "    f\"{model_name}-finetuned-inshots\",\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=3,\n",
        "    num_train_epochs=5,\n",
        "    predict_with_generate=True,\n",
        "    fp16=True,\n",
        ")\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TXPa2g9CTJC",
        "outputId": "b2e19b56-a2ee-48f0-8acc-1ff8a4a5d8e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--t5-small/snapshots/d78aea13fa7ecd06c29e3e46195d6341255065d5/config.json\n",
            "Model config T5Config {\n",
            "  \"_name_or_path\": \"t5-small\",\n",
            "  \"architectures\": [\n",
            "    \"T5WithLMHeadModel\"\n",
            "  ],\n",
            "  \"d_ff\": 2048,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 512,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"relu\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"relu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": false,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"t5\",\n",
            "  \"n_positions\": 512,\n",
            "  \"num_decoder_layers\": 6,\n",
            "  \"num_heads\": 8,\n",
            "  \"num_layers\": 6,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 200,\n",
            "      \"min_length\": 30,\n",
            "      \"no_repeat_ngram_size\": 3,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"summarize: \"\n",
            "    },\n",
            "    \"translation_en_to_de\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to German: \"\n",
            "    },\n",
            "    \"translation_en_to_fr\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to French: \"\n",
            "    },\n",
            "    \"translation_en_to_ro\": {\n",
            "      \"early_stopping\": true,\n",
            "      \"max_length\": 300,\n",
            "      \"num_beams\": 4,\n",
            "      \"prefix\": \"translate English to Romanian: \"\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.24.0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32128\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--t5-small/snapshots/d78aea13fa7ecd06c29e3e46195d6341255065d5/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
            "\n",
            "All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at t5-small.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "bLrM5zraCGq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Seq2SeqTrainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"test\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QH1PPs5-Cnsk",
        "outputId": "3eec727e-ac06-4fea-b2db-6a59174487b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cuda_amp half precision backend\n",
            "The following columns in the training set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: clean_summary, __index_level_0__, text. If clean_summary, __index_level_0__, text are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 17832\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 4\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 22290\n",
            "  Number of trainable parameters = 60506624\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='22290' max='22290' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [22290/22290 1:58:39, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rouge1</th>\n",
              "      <th>Rouge2</th>\n",
              "      <th>Rougel</th>\n",
              "      <th>Rougelsum</th>\n",
              "      <th>Gen Len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.754800</td>\n",
              "      <td>1.579784</td>\n",
              "      <td>24.305100</td>\n",
              "      <td>13.574200</td>\n",
              "      <td>20.949200</td>\n",
              "      <td>22.417100</td>\n",
              "      <td>19.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.694800</td>\n",
              "      <td>1.535118</td>\n",
              "      <td>24.756000</td>\n",
              "      <td>13.874100</td>\n",
              "      <td>21.285200</td>\n",
              "      <td>22.817300</td>\n",
              "      <td>19.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.677000</td>\n",
              "      <td>1.513046</td>\n",
              "      <td>24.768500</td>\n",
              "      <td>13.915900</td>\n",
              "      <td>21.288700</td>\n",
              "      <td>22.858800</td>\n",
              "      <td>19.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.666500</td>\n",
              "      <td>1.505894</td>\n",
              "      <td>24.995700</td>\n",
              "      <td>14.048600</td>\n",
              "      <td>21.488300</td>\n",
              "      <td>23.023700</td>\n",
              "      <td>19.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.641000</td>\n",
              "      <td>1.504159</td>\n",
              "      <td>24.918000</td>\n",
              "      <td>13.987700</td>\n",
              "      <td>21.373600</td>\n",
              "      <td>22.930300</td>\n",
              "      <td>19.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to t5-small-finetuned-inshots/checkpoint-500\n",
            "Configuration saved in t5-small-finetuned-inshots/checkpoint-500/config.json\n",
            "Model weights saved in t5-small-finetuned-inshots/checkpoint-500/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-inshots/checkpoint-500/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-inshots/checkpoint-500/special_tokens_map.json\n",
            "Saving model checkpoint to t5-small-finetuned-inshots/checkpoint-1000\n",
            "Configuration saved in t5-small-finetuned-inshots/checkpoint-1000/config.json\n",
            "Model weights saved in t5-small-finetuned-inshots/checkpoint-1000/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-inshots/checkpoint-1000/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-inshots/checkpoint-1000/special_tokens_map.json\n",
            "Saving model checkpoint to t5-small-finetuned-inshots/checkpoint-1500\n",
            "Configuration saved in t5-small-finetuned-inshots/checkpoint-1500/config.json\n",
            "Model weights saved in t5-small-finetuned-inshots/checkpoint-1500/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-inshots/checkpoint-1500/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-inshots/checkpoint-1500/special_tokens_map.json\n",
            "Saving model checkpoint to t5-small-finetuned-inshots/checkpoint-2000\n",
            "Configuration saved in t5-small-finetuned-inshots/checkpoint-2000/config.json\n",
            "Model weights saved in t5-small-finetuned-inshots/checkpoint-2000/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-inshots/checkpoint-2000/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-inshots/checkpoint-2000/special_tokens_map.json\n",
            "Deleting older checkpoint [t5-small-finetuned-inshots/checkpoint-500] due to args.save_total_limit\n",
            "Saving model checkpoint to t5-small-finetuned-inshots/checkpoint-2500\n",
            "Configuration saved in t5-small-finetuned-inshots/checkpoint-2500/config.json\n",
            "Model weights saved in t5-small-finetuned-inshots/checkpoint-2500/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-inshots/checkpoint-2500/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-inshots/checkpoint-2500/special_tokens_map.json\n",
            "Deleting older checkpoint [t5-small-finetuned-inshots/checkpoint-1000] due to args.save_total_limit\n",
            "Saving model checkpoint to t5-small-finetuned-inshots/checkpoint-3000\n",
            "Configuration saved in t5-small-finetuned-inshots/checkpoint-3000/config.json\n",
            "Model weights saved in t5-small-finetuned-inshots/checkpoint-3000/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-inshots/checkpoint-3000/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-inshots/checkpoint-3000/special_tokens_map.json\n",
            "Deleting older checkpoint [t5-small-finetuned-inshots/checkpoint-1500] due to args.save_total_limit\n",
            "Saving model checkpoint to t5-small-finetuned-inshots/checkpoint-3500\n",
            "Configuration saved in t5-small-finetuned-inshots/checkpoint-3500/config.json\n",
            "Model weights saved in t5-small-finetuned-inshots/checkpoint-3500/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-inshots/checkpoint-3500/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-inshots/checkpoint-3500/special_tokens_map.json\n",
            "Deleting older checkpoint [t5-small-finetuned-inshots/checkpoint-2000] due to args.save_total_limit\n",
            "Saving model checkpoint to t5-small-finetuned-inshots/checkpoint-4000\n",
            "Configuration saved in t5-small-finetuned-inshots/checkpoint-4000/config.json\n",
            "Model weights saved in t5-small-finetuned-inshots/checkpoint-4000/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-inshots/checkpoint-4000/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-inshots/checkpoint-4000/special_tokens_map.json\n",
            "Deleting older checkpoint [t5-small-finetuned-inshots/checkpoint-2500] due to args.save_total_limit\n",
            "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: clean_summary, __index_level_0__, text. If clean_summary, __index_level_0__, text are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1982\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to t5-small-finetuned-inshots/checkpoint-4500\n",
            "Configuration saved in t5-small-finetuned-inshots/checkpoint-4500/config.json\n",
            "Model weights saved in t5-small-finetuned-inshots/checkpoint-4500/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-inshots/checkpoint-4500/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-inshots/checkpoint-4500/special_tokens_map.json\n",
            "Deleting older checkpoint [t5-small-finetuned-inshots/checkpoint-3000] due to args.save_total_limit\n",
            "Saving model checkpoint to t5-small-finetuned-inshots/checkpoint-5000\n",
            "Configuration saved in t5-small-finetuned-inshots/checkpoint-5000/config.json\n",
            "Model weights saved in t5-small-finetuned-inshots/checkpoint-5000/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-inshots/checkpoint-5000/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-inshots/checkpoint-5000/special_tokens_map.json\n",
            "Deleting older checkpoint [t5-small-finetuned-inshots/checkpoint-3500] due to args.save_total_limit\n",
            "Saving model checkpoint to t5-small-finetuned-inshots/checkpoint-5500\n",
            "Configuration saved in t5-small-finetuned-inshots/checkpoint-5500/config.json\n",
            "Model weights saved in t5-small-finetuned-inshots/checkpoint-5500/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-inshots/checkpoint-5500/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-inshots/checkpoint-5500/special_tokens_map.json\n",
            "Deleting older checkpoint [t5-small-finetuned-inshots/checkpoint-4000] due to args.save_total_limit\n",
            "Saving model checkpoint to t5-small-finetuned-inshots/checkpoint-6000\n",
            "Configuration saved in t5-small-finetuned-inshots/checkpoint-6000/config.json\n",
            "Model weights saved in t5-small-finetuned-inshots/checkpoint-6000/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-inshots/checkpoint-6000/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-inshots/checkpoint-6000/special_tokens_map.json\n",
            "Deleting older checkpoint [t5-small-finetuned-inshots/checkpoint-4500] due to args.save_total_limit\n",
            "Saving model checkpoint to t5-small-finetuned-inshots/checkpoint-6500\n",
            "Configuration saved in t5-small-finetuned-inshots/checkpoint-6500/config.json\n",
            "Model weights saved in t5-small-finetuned-inshots/checkpoint-6500/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-inshots/checkpoint-6500/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-inshots/checkpoint-6500/special_tokens_map.json\n",
            "Deleting older checkpoint [t5-small-finetuned-inshots/checkpoint-5000] due to args.save_total_limit\n",
            "Saving model checkpoint to t5-small-finetuned-inshots/checkpoint-7000\n",
            "Configuration saved in t5-small-finetuned-inshots/checkpoint-7000/config.json\n",
            "Model weights saved in t5-small-finetuned-inshots/checkpoint-7000/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-inshots/checkpoint-7000/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-inshots/checkpoint-7000/special_tokens_map.json\n",
            "Deleting older checkpoint [t5-small-finetuned-inshots/checkpoint-5500] due to args.save_total_limit\n",
            "Saving model checkpoint to t5-small-finetuned-inshots/checkpoint-7500\n",
            "Configuration saved in t5-small-finetuned-inshots/checkpoint-7500/config.json\n",
            "Model weights saved in t5-small-finetuned-inshots/checkpoint-7500/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-inshots/checkpoint-7500/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-inshots/checkpoint-7500/special_tokens_map.json\n",
            "Deleting older checkpoint [t5-small-finetuned-inshots/checkpoint-6000] due to args.save_total_limit\n",
            "Saving model checkpoint to t5-small-finetuned-inshots/checkpoint-8000\n",
            "Configuration saved in t5-small-finetuned-inshots/checkpoint-8000/config.json\n",
            "Model weights saved in t5-small-finetuned-inshots/checkpoint-8000/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-inshots/checkpoint-8000/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-inshots/checkpoint-8000/special_tokens_map.json\n",
            "Deleting older checkpoint [t5-small-finetuned-inshots/checkpoint-6500] due to args.save_total_limit\n",
            "Saving model checkpoint to t5-small-finetuned-inshots/checkpoint-8500\n",
            "Configuration saved in t5-small-finetuned-inshots/checkpoint-8500/config.json\n",
            "Model weights saved in t5-small-finetuned-inshots/checkpoint-8500/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-inshots/checkpoint-8500/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-inshots/checkpoint-8500/special_tokens_map.json\n",
            "Deleting older checkpoint [t5-small-finetuned-inshots/checkpoint-7000] due to args.save_total_limit\n",
            "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: clean_summary, __index_level_0__, text. If clean_summary, __index_level_0__, text are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1982\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to t5-small-finetuned-inshots/checkpoint-9000\n",
            "Configuration saved in t5-small-finetuned-inshots/checkpoint-9000/config.json\n",
            "Model weights saved in t5-small-finetuned-inshots/checkpoint-9000/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-inshots/checkpoint-9000/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-inshots/checkpoint-9000/special_tokens_map.json\n",
            "Deleting older checkpoint [t5-small-finetuned-inshots/checkpoint-7500] due to args.save_total_limit\n",
            "Saving model checkpoint to t5-small-finetuned-inshots/checkpoint-9500\n",
            "Configuration saved in t5-small-finetuned-inshots/checkpoint-9500/config.json\n",
            "Model weights saved in t5-small-finetuned-inshots/checkpoint-9500/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-inshots/checkpoint-9500/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-inshots/checkpoint-9500/special_tokens_map.json\n",
            "Deleting older checkpoint [t5-small-finetuned-inshots/checkpoint-8000] due to args.save_total_limit\n",
            "Saving model checkpoint to t5-small-finetuned-inshots/checkpoint-10000\n",
            "Configuration saved in t5-small-finetuned-inshots/checkpoint-10000/config.json\n",
            "Model weights saved in t5-small-finetuned-inshots/checkpoint-10000/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-inshots/checkpoint-10000/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-inshots/checkpoint-10000/special_tokens_map.json\n",
            "Deleting older checkpoint [t5-small-finetuned-inshots/checkpoint-8500] due to args.save_total_limit\n",
            "Saving model checkpoint to t5-small-finetuned-inshots/checkpoint-10500\n",
            "Configuration saved in t5-small-finetuned-inshots/checkpoint-10500/config.json\n",
            "Model weights saved in t5-small-finetuned-inshots/checkpoint-10500/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-inshots/checkpoint-10500/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-inshots/checkpoint-10500/special_tokens_map.json\n",
            "Deleting older checkpoint [t5-small-finetuned-inshots/checkpoint-9000] due to args.save_total_limit\n",
            "Saving model checkpoint to t5-small-finetuned-inshots/checkpoint-11000\n",
            "Configuration saved in t5-small-finetuned-inshots/checkpoint-11000/config.json\n",
            "Model weights saved in t5-small-finetuned-inshots/checkpoint-11000/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-inshots/checkpoint-11000/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-inshots/checkpoint-11000/special_tokens_map.json\n",
            "Deleting older checkpoint [t5-small-finetuned-inshots/checkpoint-9500] due to args.save_total_limit\n",
            "Saving model checkpoint to t5-small-finetuned-inshots/checkpoint-11500\n",
            "Configuration saved in t5-small-finetuned-inshots/checkpoint-11500/config.json\n",
            "Model weights saved in t5-small-finetuned-inshots/checkpoint-11500/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-inshots/checkpoint-11500/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-inshots/checkpoint-11500/special_tokens_map.json\n",
            "Deleting older checkpoint [t5-small-finetuned-inshots/checkpoint-10000] due to args.save_total_limit\n",
            "Saving model checkpoint to t5-small-finetuned-inshots/checkpoint-12000\n",
            "Configuration saved in t5-small-finetuned-inshots/checkpoint-12000/config.json\n",
            "Model weights saved in t5-small-finetuned-inshots/checkpoint-12000/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-inshots/checkpoint-12000/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-inshots/checkpoint-12000/special_tokens_map.json\n",
            "Deleting older checkpoint [t5-small-finetuned-inshots/checkpoint-10500] due to args.save_total_limit\n",
            "Saving model checkpoint to t5-small-finetuned-inshots/checkpoint-12500\n",
            "Configuration saved in t5-small-finetuned-inshots/checkpoint-12500/config.json\n",
            "Model weights saved in t5-small-finetuned-inshots/checkpoint-12500/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-inshots/checkpoint-12500/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-inshots/checkpoint-12500/special_tokens_map.json\n",
            "Deleting older checkpoint [t5-small-finetuned-inshots/checkpoint-11000] due to args.save_total_limit\n",
            "Saving model checkpoint to t5-small-finetuned-inshots/checkpoint-13000\n",
            "Configuration saved in t5-small-finetuned-inshots/checkpoint-13000/config.json\n",
            "Model weights saved in t5-small-finetuned-inshots/checkpoint-13000/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-inshots/checkpoint-13000/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-inshots/checkpoint-13000/special_tokens_map.json\n",
            "Deleting older checkpoint [t5-small-finetuned-inshots/checkpoint-11500] due to args.save_total_limit\n",
            "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: clean_summary, __index_level_0__, text. If clean_summary, __index_level_0__, text are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1982\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to t5-small-finetuned-inshots/checkpoint-13500\n",
            "Configuration saved in t5-small-finetuned-inshots/checkpoint-13500/config.json\n",
            "Model weights saved in t5-small-finetuned-inshots/checkpoint-13500/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-inshots/checkpoint-13500/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-inshots/checkpoint-13500/special_tokens_map.json\n",
            "Deleting older checkpoint [t5-small-finetuned-inshots/checkpoint-12000] due to args.save_total_limit\n",
            "Saving model checkpoint to t5-small-finetuned-inshots/checkpoint-14000\n",
            "Configuration saved in t5-small-finetuned-inshots/checkpoint-14000/config.json\n",
            "Model weights saved in t5-small-finetuned-inshots/checkpoint-14000/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-inshots/checkpoint-14000/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-inshots/checkpoint-14000/special_tokens_map.json\n",
            "Deleting older checkpoint [t5-small-finetuned-inshots/checkpoint-12500] due to args.save_total_limit\n",
            "Saving model checkpoint to t5-small-finetuned-inshots/checkpoint-14500\n",
            "Configuration saved in t5-small-finetuned-inshots/checkpoint-14500/config.json\n",
            "Model weights saved in t5-small-finetuned-inshots/checkpoint-14500/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-inshots/checkpoint-14500/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-inshots/checkpoint-14500/special_tokens_map.json\n",
            "Deleting older checkpoint [t5-small-finetuned-inshots/checkpoint-13000] due to args.save_total_limit\n",
            "Saving model checkpoint to t5-small-finetuned-inshots/checkpoint-15000\n",
            "Configuration saved in t5-small-finetuned-inshots/checkpoint-15000/config.json\n",
            "Model weights saved in t5-small-finetuned-inshots/checkpoint-15000/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-inshots/checkpoint-15000/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-inshots/checkpoint-15000/special_tokens_map.json\n",
            "Deleting older checkpoint [t5-small-finetuned-inshots/checkpoint-13500] due to args.save_total_limit\n",
            "Saving model checkpoint to t5-small-finetuned-inshots/checkpoint-15500\n",
            "Configuration saved in t5-small-finetuned-inshots/checkpoint-15500/config.json\n",
            "Model weights saved in t5-small-finetuned-inshots/checkpoint-15500/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-inshots/checkpoint-15500/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-inshots/checkpoint-15500/special_tokens_map.json\n",
            "Deleting older checkpoint [t5-small-finetuned-inshots/checkpoint-14000] due to args.save_total_limit\n",
            "Saving model checkpoint to t5-small-finetuned-inshots/checkpoint-16000\n",
            "Configuration saved in t5-small-finetuned-inshots/checkpoint-16000/config.json\n",
            "Model weights saved in t5-small-finetuned-inshots/checkpoint-16000/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-inshots/checkpoint-16000/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-inshots/checkpoint-16000/special_tokens_map.json\n",
            "Deleting older checkpoint [t5-small-finetuned-inshots/checkpoint-14500] due to args.save_total_limit\n",
            "Saving model checkpoint to t5-small-finetuned-inshots/checkpoint-16500\n",
            "Configuration saved in t5-small-finetuned-inshots/checkpoint-16500/config.json\n",
            "Model weights saved in t5-small-finetuned-inshots/checkpoint-16500/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-inshots/checkpoint-16500/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-inshots/checkpoint-16500/special_tokens_map.json\n",
            "Deleting older checkpoint [t5-small-finetuned-inshots/checkpoint-15000] due to args.save_total_limit\n",
            "Saving model checkpoint to t5-small-finetuned-inshots/checkpoint-17000\n",
            "Configuration saved in t5-small-finetuned-inshots/checkpoint-17000/config.json\n",
            "Model weights saved in t5-small-finetuned-inshots/checkpoint-17000/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-inshots/checkpoint-17000/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-inshots/checkpoint-17000/special_tokens_map.json\n",
            "Deleting older checkpoint [t5-small-finetuned-inshots/checkpoint-15500] due to args.save_total_limit\n",
            "Saving model checkpoint to t5-small-finetuned-inshots/checkpoint-17500\n",
            "Configuration saved in t5-small-finetuned-inshots/checkpoint-17500/config.json\n",
            "Model weights saved in t5-small-finetuned-inshots/checkpoint-17500/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-inshots/checkpoint-17500/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-inshots/checkpoint-17500/special_tokens_map.json\n",
            "Deleting older checkpoint [t5-small-finetuned-inshots/checkpoint-16000] due to args.save_total_limit\n",
            "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: clean_summary, __index_level_0__, text. If clean_summary, __index_level_0__, text are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1982\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to t5-small-finetuned-inshots/checkpoint-18000\n",
            "Configuration saved in t5-small-finetuned-inshots/checkpoint-18000/config.json\n",
            "Model weights saved in t5-small-finetuned-inshots/checkpoint-18000/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-inshots/checkpoint-18000/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-inshots/checkpoint-18000/special_tokens_map.json\n",
            "Deleting older checkpoint [t5-small-finetuned-inshots/checkpoint-16500] due to args.save_total_limit\n",
            "Saving model checkpoint to t5-small-finetuned-inshots/checkpoint-18500\n",
            "Configuration saved in t5-small-finetuned-inshots/checkpoint-18500/config.json\n",
            "Model weights saved in t5-small-finetuned-inshots/checkpoint-18500/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-inshots/checkpoint-18500/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-inshots/checkpoint-18500/special_tokens_map.json\n",
            "Deleting older checkpoint [t5-small-finetuned-inshots/checkpoint-17000] due to args.save_total_limit\n",
            "Saving model checkpoint to t5-small-finetuned-inshots/checkpoint-19000\n",
            "Configuration saved in t5-small-finetuned-inshots/checkpoint-19000/config.json\n",
            "Model weights saved in t5-small-finetuned-inshots/checkpoint-19000/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-inshots/checkpoint-19000/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-inshots/checkpoint-19000/special_tokens_map.json\n",
            "Deleting older checkpoint [t5-small-finetuned-inshots/checkpoint-17500] due to args.save_total_limit\n",
            "Saving model checkpoint to t5-small-finetuned-inshots/checkpoint-19500\n",
            "Configuration saved in t5-small-finetuned-inshots/checkpoint-19500/config.json\n",
            "Model weights saved in t5-small-finetuned-inshots/checkpoint-19500/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-inshots/checkpoint-19500/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-inshots/checkpoint-19500/special_tokens_map.json\n",
            "Deleting older checkpoint [t5-small-finetuned-inshots/checkpoint-18000] due to args.save_total_limit\n",
            "Saving model checkpoint to t5-small-finetuned-inshots/checkpoint-20000\n",
            "Configuration saved in t5-small-finetuned-inshots/checkpoint-20000/config.json\n",
            "Model weights saved in t5-small-finetuned-inshots/checkpoint-20000/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-inshots/checkpoint-20000/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-inshots/checkpoint-20000/special_tokens_map.json\n",
            "Deleting older checkpoint [t5-small-finetuned-inshots/checkpoint-18500] due to args.save_total_limit\n",
            "Saving model checkpoint to t5-small-finetuned-inshots/checkpoint-20500\n",
            "Configuration saved in t5-small-finetuned-inshots/checkpoint-20500/config.json\n",
            "Model weights saved in t5-small-finetuned-inshots/checkpoint-20500/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-inshots/checkpoint-20500/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-inshots/checkpoint-20500/special_tokens_map.json\n",
            "Deleting older checkpoint [t5-small-finetuned-inshots/checkpoint-19000] due to args.save_total_limit\n",
            "Saving model checkpoint to t5-small-finetuned-inshots/checkpoint-21000\n",
            "Configuration saved in t5-small-finetuned-inshots/checkpoint-21000/config.json\n",
            "Model weights saved in t5-small-finetuned-inshots/checkpoint-21000/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-inshots/checkpoint-21000/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-inshots/checkpoint-21000/special_tokens_map.json\n",
            "Deleting older checkpoint [t5-small-finetuned-inshots/checkpoint-19500] due to args.save_total_limit\n",
            "Saving model checkpoint to t5-small-finetuned-inshots/checkpoint-21500\n",
            "Configuration saved in t5-small-finetuned-inshots/checkpoint-21500/config.json\n",
            "Model weights saved in t5-small-finetuned-inshots/checkpoint-21500/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-inshots/checkpoint-21500/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-inshots/checkpoint-21500/special_tokens_map.json\n",
            "Deleting older checkpoint [t5-small-finetuned-inshots/checkpoint-20000] due to args.save_total_limit\n",
            "Saving model checkpoint to t5-small-finetuned-inshots/checkpoint-22000\n",
            "Configuration saved in t5-small-finetuned-inshots/checkpoint-22000/config.json\n",
            "Model weights saved in t5-small-finetuned-inshots/checkpoint-22000/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-inshots/checkpoint-22000/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-inshots/checkpoint-22000/special_tokens_map.json\n",
            "Deleting older checkpoint [t5-small-finetuned-inshots/checkpoint-20500] due to args.save_total_limit\n",
            "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: clean_summary, __index_level_0__, text. If clean_summary, __index_level_0__, text are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1982\n",
            "  Batch size = 4\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=22290, training_loss=1.7047613897789964, metrics={'train_runtime': 7119.9615, 'train_samples_per_second': 12.523, 'train_steps_per_second': 3.131, 'total_flos': 2.0903537007919104e+16, 'train_loss': 1.7047613897789964, 'epoch': 5.0})"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model('/content/drive/MyDrive/InShorts/model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ye7Ceg6TOMu4",
        "outputId": "ee7df471-a57f-47e5-ac7e-659e5303582b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/InShorts/model\n",
            "Configuration saved in /content/drive/MyDrive/InShorts/model/config.json\n",
            "Model weights saved in /content/drive/MyDrive/InShorts/model/pytorch_model.bin\n",
            "tokenizer config file saved in /content/drive/MyDrive/InShorts/model/tokenizer_config.json\n",
            "Special tokens file saved in /content/drive/MyDrive/InShorts/model/special_tokens_map.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "hub_model_id = \"/content/drive/MyDrive/InShorts/model\"\n",
        "summarizer = pipeline(\"summarization\", model=hub_model_id)"
      ],
      "metadata": {
        "id": "T_HXyMVuDk66"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summarizer('Washington [US], October 31 (ANI): US President Joe Biden lost his temper with Volodymyr Zelenskyy in June during a phone conversation when he asked for more military aid, NBC News reported on Monday, citing sources familiar with the call. The report said Biden routinely calls Zelenskyy when the US announces new aid packages for Ukraine. But the June call was different. Biden had barely finished informing Zelenskyy that he had approved another USD 1 billion in military assistance for Ukraine when his counterpart started asking for extra help Kyiv needs but isn’t getting, the report said. Biden raised his voice, and as per the NBC report said Zelenskyy could “show a little more gratitude.” Prior to the June 15 phone call, Biden’s dissatisfaction with Zelenskyy had been building for weeks, the sources said. According to them, the US president and a number of his aides believed that Washington was doing everything possible and as quickly as possible, but Zelenskyy continued to publicly pay attention only to what was not being done. After Zelenskyy was rebuffed during the June call, Zelenskyy publicly delivered a video message thanking Biden for the assistance and defusing the tensions. “I had an important conversation with US President Biden today,” NBC quoted Ukraine’s president in videotaped remarks. “I am grateful for this support. It is especially important for our defence in Donbas.” The United States has been a leading provider of security assistance to Ukraine, particularly since the start of the Russia-Ukraine conflict on February 24. This report on the Biden-Zelenskyy phone call comes two days after Washington announced USD 275 million in additional military assistance for Ukraine. “This drawdown will bring the total US military assistance for Ukraine to an unprecedented level of more than USD 18.5 billion since the beginning of the Administration,” the US State Department said in a statement. The United States, in 2022, provided more advanced defence equipment to Ukraine, as well as greater amounts of previously provided equipment, according to a Congressional Research Service report. According to Pentagon, US security assistance committed to Ukraine, includes High Mobility Artillery Rocket Systems, Stinger anti-aircraft systems, Javelin anti-armour systems and Mi-17 helicopters. Ukrainian officials have sought to acquire other advanced systems, including fighter aircraft, anti-ship, and additional air defence and anti-missile capabilities. (ANI) This report is auto-generated from ANI news service. ThePrint holds no responsibility for its content.')"
      ],
      "metadata": {
        "id": "YfflkXRUXBM_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "073709a1-fcec-44e0-c684-842cdd7ac1ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (573 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'summary_text': \"US President Joe Biden lost his temper with US President Volodymyr Zelenskyy during a phone conversation in June when he asked for more military aid, NBC News reported on Monday. Biden had barely finished informing him that he had approved another USD 1 billion in military assistance for Ukraine when his counterpart started asking for extra help Kyiv needs but isn't getting, the report said.\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "75wz78feYWUG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9b7ad4aabbe741f18c154d9bd80fd5da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_83a669bd26094721bbf0bb8d280b3d05",
              "IPY_MODEL_bd4de906555f40afbec94547f6a6bef2",
              "IPY_MODEL_0e7e1786fcf9455096a77d775ca1bc3c"
            ],
            "layout": "IPY_MODEL_c6409341560c4815832fc97b57712598"
          }
        },
        "83a669bd26094721bbf0bb8d280b3d05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52233d0e19b341ba9af34ea427c4625d",
            "placeholder": "​",
            "style": "IPY_MODEL_d938f1c9bb46401aad40ee6c29b31581",
            "value": " 94%"
          }
        },
        "bd4de906555f40afbec94547f6a6bef2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_478399f05a6d40aa8adc2c7400946b64",
            "max": 18,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_89b3b7757f384910831587ab2ef51727",
            "value": 17
          }
        },
        "0e7e1786fcf9455096a77d775ca1bc3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43a53d1ea5444527a7880a77888acc67",
            "placeholder": "​",
            "style": "IPY_MODEL_6495e9dd90254951a2c7c1974ee94025",
            "value": " 17/18 [00:24&lt;00:01,  1.37s/ba]"
          }
        },
        "c6409341560c4815832fc97b57712598": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52233d0e19b341ba9af34ea427c4625d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d938f1c9bb46401aad40ee6c29b31581": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "478399f05a6d40aa8adc2c7400946b64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89b3b7757f384910831587ab2ef51727": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "43a53d1ea5444527a7880a77888acc67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6495e9dd90254951a2c7c1974ee94025": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2b3b24a7a1284f8490c876659726ff6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a222c04b91cb4b6f9ecd2872f675b478",
              "IPY_MODEL_0b451ad8e7fc4606bff152335fd75bd0",
              "IPY_MODEL_ebdb75fcefd34952b57936c49878a957"
            ],
            "layout": "IPY_MODEL_97b57c6de31b4aa6bd076349c8be97cf"
          }
        },
        "a222c04b91cb4b6f9ecd2872f675b478": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8dd1d604e25b4a5e8c31635706bb9461",
            "placeholder": "​",
            "style": "IPY_MODEL_8937b94f34e44105b92a6a1ae33b9dea",
            "value": " 50%"
          }
        },
        "0b451ad8e7fc4606bff152335fd75bd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca2b7bf9d5d74777ae9babf688a0689e",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_360bf60a0a1b4a688270eab7c1ad0d34",
            "value": 1
          }
        },
        "ebdb75fcefd34952b57936c49878a957": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ef1d4afb41b4ff08358cedf27122e8a",
            "placeholder": "​",
            "style": "IPY_MODEL_7106a86cb69b4c378859850587d89c69",
            "value": " 1/2 [00:02&lt;00:01,  1.27s/ba]"
          }
        },
        "97b57c6de31b4aa6bd076349c8be97cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8dd1d604e25b4a5e8c31635706bb9461": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8937b94f34e44105b92a6a1ae33b9dea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca2b7bf9d5d74777ae9babf688a0689e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "360bf60a0a1b4a688270eab7c1ad0d34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9ef1d4afb41b4ff08358cedf27122e8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7106a86cb69b4c378859850587d89c69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}